{"posts":[{"title":"纯CSS实现元素水平无限滚动","content":"实现原理 将要滚动的元素复制一份放在后面 然后使用动画将元素滚动到50%的位置后瞬间将滚动位置置为0 效果 const list = [ { avatar: headerBg, text: '1纸类 累计减碳1吨，相当于回收10450 件快递箱', }, { avatar: headerBg, text: '2纸类 累计减碳1吨，相当于回收10450 件快递箱', }, ] export default function Index() { return ( &lt;View className={classes.Index}&gt; &lt;View className={classNames(classes.container)}&gt; &lt;View className={classNames(classes.group, classes.scroll)}&gt; { list.map((item) =&gt; ( &lt;View className={classNames( classes.item, )} &gt; &lt;Image src={item.avatar} className={classes.image} /&gt; &lt;View className={classes.text}&gt;{item.text}&lt;/View&gt; &lt;/View&gt; )) } &lt;/View&gt; &lt;View className={classNames(classes.group, classes.scroll)}&gt; { list.map((item) =&gt; ( &lt;View className={classNames( classes.item, )} &gt; &lt;Image src={item.avatar} className={classes.image} /&gt; &lt;View className={classes.text}&gt;{item.text}&lt;/View&gt; &lt;/View&gt; )) } &lt;/View&gt; &lt;/View&gt; &lt;/View&gt; ) } .Index { width: 100vh; overflow: hidden; } .container { display: flex; flex-wrap: nowrap; width: max-content; } .group { display: flex; flex-wrap: nowrap; width: max-content; padding-left: 20px; } @keyframes scroll { 0% { transform: translateX(0); } 100% { transform: translateX(-100%); } } .scroll { will-change: transform; animation: scroll 10s linear infinite normal; } ","link":"https://www.youmeng.me/post/chun-css-shi-xian-yuan-su-shui-ping-wu-xian-gun-dong/"},{"title":"前端监控系列3 ｜ 如何衡量一个站点的性能好坏","content":" 原文链接： URL Source: https://juejin.cn/post/7130830761137012766 Markdown Content: 作者：彭莉，火山引擎 APM 研发工程师。2020年加入字节，负责前端监控 SDK 的开发维护、平台数据消费的探索和落地。 背景 你知道有多少用户没等到页面首屏出现就离开了吗？性能不佳会对业务目标产生负面影响。比如， BBC 发现他们的网站加载时间每增加一秒，他们就会失去 10% 的用户。高性能站点比低性能站点更能吸引和留住用户，而留住用户对于提高用户转化率至关重要。 这篇文章就是以此为背景，介绍字节内部是如何衡量站点性能的，如何依靠性能监控定位线上站点性能问题的。 如何衡量站点性能 站点性能好坏的表现形式是多样的，不是单纯通过页面加载速度、页面渲染速度就能衡量，而是要关注从页面开始加载到被关闭的整个过程中，用户对性能的感知。一个页面，即使很快渲染，如果对用户的交互迟迟没有响应，那么在用户心中这个站点的性能依然很差。 站点性能一般可以分为两类，一类是首屏性能，另一类是运行时性能。前者衡量的是页面从加载开始到可以稳定交互的性能情况，后者衡量的是页面稳定后到页面关闭的性能情况。 首屏性能 早在 2012 年， Web 性能工作组[1] 就针对页面加载场景制定了加载过程模型，用来衡量页面加载各个阶段的耗时情况，从而衡量页面加载的性能。具体的加载过程模型如图所示： 这个模型定义了页面加载开始到页面加载完成整个过程的各个时间点，除了正常的初始化并且拉取到主文档的时间点以外，还包括了解析渲染的详细时间点。比如： domLoading 代表 开始解析的时间点 domInteractive 代表 DOM 解析完成、开始加载内嵌资源的时间点 domComplete 代表 文档解析完成的时间点 loadEventStart 代表 load 事件被触发的时间点 虽然开发者可以根据这些时间点来衡量页面加载时的性能情况，但是线上用户其实感知不到这些时间点的区别。对于用户而言，只能感知到页面何时开始渲染、何时渲染出主要内容、何时可以交互、以及交互时是否有延迟。 那么针对用户感知到的这四个阶段，有没有可用于衡量的指标呢？ 何时开始渲染：FP &amp;&amp; FCP FP：First Paint，首次渲染的时间点。FP 时间点之前，用户看到的都是没有任何内容的白色屏幕。 FCP：First Contentful Paint，首次有实际内容渲染的时间点。 这两个指标都来源于 Paint Timing[2] 标准， 这个标准主要是记录在页面加载期间的一些关键时间点。通过这两个指标，就可以衡量页面何时开始渲染内容了。 何时渲染出主要内容：FMP &amp;&amp; LCP &amp;&amp; SI FMP：First Meaningful Paint，完成首次有意义内容绘制的时间点。 LCP：Largest Contentful Paint，最大的内容在可视区域内变得可见的时间点。 SI：Speed Index，衡量页面可视区域的加载速度，反映页面的加载体验差异。 有了这三个指标，就可以衡量页面何时渲染出主要内容了。不过业界有测试得出， LCP 非常近似于 FMP 的时间点，同时 FMP 性能消耗较大，且会因为一些细小的变化导致数值巨大波动，所以推荐使用 LCP。 而 SI 因为计算复杂，指标难以解释，所以一般只在实验室环境下使用。 何时可以交互：TTI &amp;&amp; TBT TTI: Time to Interactive，页面从开始加载到主要子资源完成渲染，并能够快速、可靠地响应用户输入的时间点。 TBT: Total Blocking Time，页面从 FCP 到 TTI 之间的阻塞时间，一般用来量化主线程在空闲之前的繁忙程度。 TTI 虽然可以衡量页面可以交互的时间点，但是却无法感知这个期间浏览器的繁忙状态。而结合 TBT ，就能帮助理解在加载期间，页面无法响应用户输入的时间有多久。 交互时是否有延迟：FID &amp;&amp; MPFID FID：First Input Delay，用户第一次与页面交互（例如当他们单击链接、点按按钮等操作）直到浏览器对交互作出响应，并且实际能够开始处理事件程序所经过的时间。 MPFID: Max Potential First Input Delay，记录在页面加载过程中用户和页面进行首次交互操作可能花费的最长时间。 MPFID 是一个虚拟的可能的延迟时间，而FID是用户真实的首次交互的延迟时间。所以一般推荐使用FID，它是用户对页面交互性和响应性的第一印象。良好的第一印象有助于用户建立对整个应用的良好印象。同时在页面加载阶段，资源的处理任务最重，最容易产生输入延迟。 至此，通过上面每个阶段的指标，基本可以实现全面衡量首屏性能。那么运行时的性能又可以怎样衡量呢？ 运行时性能 运行时性能一般可以通过Long tasks 和 Input Delay来感知。Long tasks主要是衡量主线程的繁忙情况，而 Input Delay 主要是衡量用户交互的延迟情况。 Long tasks 如果一个任务在主线程上运行超过 50 毫秒，那么它就是 Long task。如果可以收集到运行时的所有Long tasks，就能知道运行时的性能情况。在具体实践中，可以关注耗时较长的Long task，将它和用户行为关联在一起，可以有效帮助定位线上卡顿的原因。 Input Delay 它源于 Event Timing[3] 标准，这个标准主要是帮助深入了解由用户交互触发的某些事件的延迟，通过计算用户输入和处理输入后的页面绘制时间的差值来感知延迟时间。这些延迟通常是由于开发人员代码编写不当，引起 JS 执行时间过长而产生的。 性能指标的计算原理 页面性能相关的指标都有了，那么如何采集这些数据呢？ 采集页面加载过程的各阶段耗时 页面加载过程中的时间点主要依赖 Navigation Timing[4] 标准，这个标准后来升级到了2.0版本， 对应 Navigation Timing 2[5] 标准，两者虽然不尽相同，但是可计算出的指标基本一致。在浏览器中可以通过下面的方式获取： // navigation timing const timing = window.performance.timing // navigation timing 2 performance.getEntriesByType('navigation') 基于这些数据，不仅可以计算出 DNS / TCP / Request 等耗时，还可以计算出 DOMReady / DOMParse / Load 等耗时。 采集 FP &amp;&amp; FCP FP 和 FCP 可以通过浏览器提供的 API 直接获取，所以采集原理并不复杂。如果页面已经完成了首次绘制和首次内容绘制，可以使用下面的方式直接获取。 window.performance.getEntriesByType('paint') // or window.performance.getEntriesByName('first-paint') window.performance.getEntriesByName('first-contentful-paint') 但是如果页面还没有开始首次绘制，就需要通过监听获取。 const observer = new PerformanceObserver(function(list) { const perfEntries = list.getEntries(); for (const perfEntry of perfEntries) { // Process entries // report back for analytics and monitoring // ... } }); // register observer for paint timing notifications observer.observe({entryTypes: [&quot;paint&quot;]}); 采集 LCP LCP 主要依赖 PerformanceObserver，具体监听方式如下： new PerformanceObserver((entryList) =&gt; { for (const entry of entryList.getEntries()) { console.log('LCP candidate:', entry.startTime, entry); } }).observe({type: 'largest-contentful-paint', buffered: true}); 浏览器会多次报告 LCP ，而一般真正的 LCP 是用户交互前最近一次报告的 LCP ，因为交互往往会改变用户可见的内容，所以用户交互后新报告的 LCP 不再符合 LCP 的指标定义。 采集 FMP 与 FP / FCP / LCP 相比， FMP 的采集相对比较复杂，它需要通过算法计算得出，而业界并没有统一的算法。不过比较认可的一个计算 FMP 的方式是「认定页面在加载和渲染过程中最大布局变动之后的那个绘制时间即为当前页面的 FMP 」。由于在页面渲染过程中，「 DOM 结构变化的时间点」和与之对应的「渲染的时间点」近似相同，所以字节内部计算 FMP 的方式是：计算出 DOM 结构变化最剧烈的时间点，即为 FMP。具体步骤为： 通过 MutationObserver 监听每一次页面整体的 DOM 变化，触发 MutationObserver 的回调 在回调计算出当前 DOM 树的分数 在结算时，通过对比得出分数变化最剧烈的时刻，即为 FMP 采集 TTI &amp;&amp; TBT 与 FMP 相似，浏览器也没有提供直接获取 TTI 的 API ，不过针对如何计算 TTI 有详细的描述，实现对应描述就可以得出 TTI 的时间点。具体的描述是：先找到 FCP 的时间点，再往前找到一个安静窗口。安静窗口需要满足三个条件: 1) 没有 Long task。2)窗口中正在处理的 GET 请求不超过两个。3) 窗口时间窗读应该至少 5s。 窗口前的最后一个长任务的结束时间就是 TTI 。 而通过计算 FCP 和 TTI 之间的长任务的阻塞时间的总和，就能得出 TBT 。 阻塞时间是 Long task 中超过 50ms 后的任务耗时。 采集 FID &amp;&amp; MPFID FID 同样依赖 PerformanceObserver，具体监听方式如下： new PerformanceObserver(function(list, obs) { const firstInput = list.getEntries()[0]; // Measure the delay to begin processing the first input event. const firstInputDelay = firstInput.processingStart - firstInput.startTime; // Measure the duration of processing the first input event. // Only use when the important event handling work is done synchronously in the handlers. const firstInputDuration = firstInput.duration; // Obtain some information about the target of this event, such as the id. const targetId = firstInput.target ? firstInput.target.id : 'unknown-target'; // Process the first input delay and perhaps its duration... // Disconnect this observer since callback is only triggered once. obs.disconnect(); }).observe({type: 'first-input', buffered: true}); MPFID 是 FCP 之后最长的长任务耗时，可以通过监听 FCP 之后的 Long tasks，对比拿到最长的长任务就是 MPFID 。 虽然浏览器提供了足够的 API 来帮助采集各个性能指标，但是在 JS 中计算具体指标要更为复杂。原因有两点：一是 API 报告的内容和指标本身的定义有部分差异，所以计算时要处理这些差异；二是 部分场景下浏览器不会报告对应内容，这些场景下需要模拟测量。 怎样评估站点整体的性能好坏 虽然有众多性能指标，但是每个性能指标评估的都是单一方面，如何整体来看站点的性能是好是坏呢？ 对于每个单一指标，是否有标准去定义指标的值在具体哪个范围内能算优秀？线上的站点性能应该重点考量哪些性能指标？各个性能指标的权重占多少合适呢？ 性能指标基准线 Google 提供了各个性能指标的基准线，有一定的参考意义。为什么只说是有一定参考意义？首先基准线本身是在变化的，随着指标计算的逐渐更新以及软件硬件的更新，基准线也会有一定的调整。其次用户的使用场景对性能指标也会有很大的影响，比如 iOS 用户上报的性能指标一般都优于 Android 用户上报的性能指标。 下方是目前字节内部使用的部分性能指标基准线，基本对齐 Google 建议的基准线，通过这些数据可以分析站点的性能达标率情况。 衡量站点满意度 站点满意度的衡量除了要考虑常规的性能指标外，还要考虑体验类的指标，比如专门衡量视觉稳定性的指标 CLS。 线上的站点满意度衡量，一般会在参考lighthouse的满意度计算规则的基础上，去除一些推荐在实验室环境测量的指标的权重。 下方是目前字节使用的线上站点性能满意度的权重计算公式，去除了SI 和 TBT这两个不推荐在线上环境测量的指标。 那么有了一个站点满意度以后，我们终于能知道一个站点的性能好坏了。那么假设性能不好，我们应该怎样优化？ 如何优化站点性能 通常，我们可以从性能指标下手去做针对性的优化。虽然指标各不相同，但是优化的思路是相通的。在了解清楚指标的依赖项以后，通过优化指标的相关依赖项，就能快速优化性能指标，从而提升站点性能。 说起来比较抽象，举个例子：比如当我们想要优化 TTI ，根据刚刚提到的 TTI 的计算方式，可以得出 TTI 的依赖项主要包含 FCP 、请求和 Long tasks，那么尽快的渲染、尽早的请求、请求尽快结束、避免长任务就是优化的关键。关于指标的具体优化措施的内容比较多，将在后续的文章中展开介绍。了解全面的优化措施固然重要，但把每个措施都做一遍并不一定能够高效地解决站点面临的关键性能问题。如何****立竿见影、具有针对性的去优化？ 通过还原用户加载时的情况来帮助定位性能问题是一个思路。 利用线上监控定位性能问题 一般情况下，前端监控除了监控性能指标以外，还会监控请求和资源的加载以及 Long tasks 等数据，这些数据可以帮助还原用户的加载现场，帮助找到蛛丝马迹。比如下面这个例子， 多项性能指标都很差。通过监控平台还原出的资源加载瀑布图， 可以看出绝大部分时间都耗在了拉取资源上 。 那么就可以初步得出性能优化方案，将优化措施侧重在资源优化上，比如缩小JS文件体积、延迟加载未使用的JS代码等等。 线上监控帮助定位性能问题的例子还有很多，这里不一一介绍了。截图中使用的是字节内部的前端监控平台，目前这套解决方案已同步在火山引擎上，接入即可对 Web 端真实数据进行实时监控、报警归因、聚类分析和细节定位，解决白屏、性能瓶颈、慢查询等关键问题，欢迎体验。 扫描下方二维码，立即申请免费使用⬇️ 相关资料 [1] Web性能工作组：www.w3.org/webperf/ [2] Paint Timing：w3c.github.io/paint-timin… [3] Event Timing: w3c.github.io/event-timin… [4] Navigation Timing: www.w3.org/TR/navigati… [5] Navigation Timing 2: www.w3.org/TR/navigati… ","link":"https://www.youmeng.me/post/qian-duan-jian-kong-xi-lie-3-or-ru-he-heng-liang-yi-ge-zhan-dian-de-xing-neng-hao-pi/"},{"title":"前端监控系列2 ｜ 聊聊 JS 错误监控那些事儿","content":" 原文链接：URL Source: https://juejin.cn/post/7129451832396480525 Markdown Content: 作者：彭莉，火山引擎 APM 研发工程师。2020年加入字节，负责前端监控 SDK 的开发维护、平台数据消费的探索和落地。 有必要针对 JS 错误做监控吗？ 我们可以先假设不对 JS 错误做监控，试想会出现什么问题？JS 错误可能会导致渲染出错、用户操作意外终止，如果没有 JS 错误监控，开发者完全感知不到线上这些异常情况。特别是像电商、支付这类业务，用户无法下单和付款。即便站点有反馈渠道，但是等到有用户反馈的时候，说明影响面已经不小了。因此像 JS 错误监控这类异常监控的存在，就是为了能及时发现线上问题、帮助快速定位问题，从而提升站点稳定性。 如何监控 JS 错误 大多数的 JS 错误都是由 JS 引擎自动生成的，比如 TypeError ，常常在值的类型不是预期的类型时触发、SyntaxError 常常在 JS 引擎解析遇到无效语法时触发。对于一些可预见的错误，通常可以使用 try/catch 捕获，而一般不可预见的错误都抛到了全局，因此可以通过监听全局的 error 事件收集到 JS 错误。 const handleError = (ev: ErrorEvent) =&gt; report(normalizeError(ev)) window.addEventListener('error', handleError) 不过浏览器中未处理的 Promise 错误比较特殊，它需要额外监听全局 unhandledrejection 事件来收集。 const handleRejection = (ev: PromiseRejectionEvent) =&gt; report(normalizeException(ev)) window.addEventListener('unhandledrejection', handleRejection) 通过上面的全局监听，我们可以采集到错误的基本信息，包括错误类型、错误信息（错误的简短描述）、错误的堆栈、引发此错误的行列号和文件路径等信息。不过这些信息都太过简略，无法帮助定位问题，无法感知到用户做了怎样的操作触发了这个错误、用户当前的浏览器型号、系统版本是怎样的、用户当前在哪个页面以及是通过怎样的方式进到页面的。 如何帮助定位问题 我们需要收集更多的 JS 错误发生时/发生前的上下文，为排查 JS 错误提供更多的思路。 怎样采集用户当前的环境信息 环境信息包括用户当前的浏览器类型和版本、系统类型和版本、设备品牌等信息。监控 SDK 主要是通过采集 UserAgent 来获取基础信息，但是解析出具体浏览器、系统和设备品牌其实是十分复杂的，具体的解析工作需要由服务端承担。 有了这些数据，我们就能很快从单个 JS 错误的分布情况判断出这个 JS 错误的影响范围，特别是如果这个 JS 错误是一个兼容性问题，一眼就能看出来，比如它只发生在特定浏览器上。 怎样为堆栈不完整的错误补充更多上下文 同步的错误通常是带有完整的堆栈信息的，但是异步的堆栈却只包含极少的堆栈信息。举个例子， 在页面上增加一个按钮，按钮的点击会触发如下一段代码。 const triggerJSError = () =&gt; { const data = { not: { found: 'test' }, } delete data.not console.log(data.not.found) } 这种同步代码触发的 JS 错误的堆栈能提供很多信息。比如在这个例子中，从堆栈中可以看出这个错误是经由 click 事件，而后触发了 triggerJSError 方法，最后发生了这个 JS 错误。 但是异步代码的报错却很难提供更多的信息。比如下面这个例子，错误由异步调用触发，从报错的堆栈里完全看不出来它是经由 click 事件，也看不出来是触发了 triggerJSError 方法。 const triggerJSError = () =&gt; { const data = { not: { found: 'test' }, } delete data.not + setTimeout(() =&gt; { console.log(data.not.found) + }) } 这是浏览器本身的事件循环机制导致的，异步任务需要等到同步任务执行完成后，再从异步队列里取出异步任务并执行，这个时候是无法沿着调用栈回溯这个异步任务的创建时的堆栈信息的。 为了更方便地排查这类错误，监控 SDK 会对一些全局的异步 API 以及全局事件 API 进行 try/catch包装，捕获到错误时补充 API 调用信息，再原封不动地将错误抛出去。虽然堆栈信息并没有填补完整，但是能提供一些辅助信息，比如 当前这个异步调用的JS 错误是经由哪个 API 调用，最终触发了这个 JS 错误的。 关于采集 JS 错误的部分看起来已经结束了？但当我们看线上真实的JS错误时，发现线上错误的堆栈难以理解，方法名都被压缩过了，文件名也变成了打包后的文件名，无法提供有用的信息。 那么监控平台是如何做到错误一上传就能显示原始堆栈的呢？ 如何自动解析出原始堆栈 线上的 JS 错误堆栈为什么看不懂 研发编写的代码与线上实际运行的代码之间存在着很多处理，比如： 打包并压缩代码。 将多个 JS 文件打包成一个 JS 文件来减少资源请求数量；通过缩短变量名、去除空格和其他复杂的压缩方式来减少资源体积，以便更快的加载 JS 文件； 兼容处理。 工程师往往热衷使用新的 JS 特性。但是由于浏览器对这些特性支持度低，在编译时，往往需要利用 Babel 等工具将这些新特性转换成更兼容的形式； 从另一种语言编译成 JS 。使用另一种语言编写，最终编译成 JS 。比如 TypeScript、PureScript 等等。 这些处理不仅可以提升编码体验，还能优化性能、提升用户体验。 当然有利就有弊，这也导致线上的代码与最初编写的代码相差甚远，让排查问题就变得非常棘手，而source map 正是用来解决这个问题的。 什么是 source map 简单来说，source map 维护了混淆后的代码行列与原代码行列的映射关系，就算只知道混淆后的堆栈信息，也能通过它得到原始堆栈信息，从而定位到真实的报错位置。 下方是一个source map 的示例，它通常包含 version / file / sources / mappings 等等字段，这些字段里也隐含着它为什么能反解出原始代码的奥秘。 sources 包含转换前的文件路径，names 包含转换前的所有变量名和属性名，sourcesContent 包含转换前文件的内容，file 包含转换后的文件名。mappings 字段看起来很神秘，简而言之，mappings 字段维护的是压缩代码到源代码之间的映射关系，可以映射到源代码的任何部分，包括标识符、运算符、函数调用等等。它分为三层， 一层是行对应， 一层是位置对应，还有一层是位置转换，以 VLQ 编码表示位置对应的转换前的源码位置。这样就能实现从混淆代码到源码的映射关系，从而实现堆栈反解。在以前的版本中，使用的并不是 VLQ 编码，最终生成的 source map 文件很大，可能是实际文件的10倍左右。在后来的版本才引入了 Base64 VLQ 编码，source map 的文件体积才有所优化。 常规的监控平台都会提供自动上传 source map 的工具，这样 JS 错误上报到平台后就能自动显示原始错误的堆栈。 下面这个截图就是反解成功后展示的原始堆栈示例，从原始堆栈可以看出，这个 JS 错误是因为 250 行的 blankInfo 没有判空导致。 现在原始堆栈也有了，错误的上下文信息也有了。打开监控平台一看，发现确实监控到了很多的JS错误，但是有很多重复的错误，一眼望不到头。 有没有什么办法，能够只看到不同的错误呢？毕竟从研发的角度讲，无论一个错误上报千次万次，终究都只是对应一个需要修复的问题。 如何判断两个错误是否相同 假设能做到这一点，那么就能将相同的错误归类在一起，研发看到的就是每一个不同的错误，就能减少噪音。但是如果聚合的方式有问题，就会导致不同的 JS 错误聚合在了一起，这样可能造成错误的遗漏。 那么怎样的聚合算法才是合适的呢？ same name + same message !== same error 在上报的错误属性中，只有 name 和 message 是标准属性，其他属性都是非标准属性，是不是使用这两个字段聚合错误就可以？ 在实际应用中，我们发现仅靠 name 和 message 并不能做到有效聚合错误。两个错误 name 和 message 相同，但是可能来源于不同的代码段。这样可能导致我们修复了其中一个错误后，误以为相关的所有错误都被修复了，从而遗漏错误。 将堆栈信息纳入聚合算法中 在实际聚合算法中，我们将反解后的堆栈纳入了计算，将堆栈拆分为一系列的 frame， 更细致的提取堆栈特征，在每一个 frame 内重点关注其调用函数名、调用文件名以及当前执行的代码行，如果这些信息都相同，可以认为是同一个错误。 为了方便识别，我们会利用上述信息，通过 hash 计算最后生成一个 issueId 作为我们识别相同错误的标识。生成 hash 的过程比较复杂，除了常规提取计算外，会针对递归调用、匿名路径、匿名函数等进行跳过，也会避开某些计算开销过大的 case 。 久而久之，监控平台上出现了很多 JS 错误，但是这些错误好多都是已经在处理的错误，有没有办法能只在出现新的 JS 错误的时候通知到我呢？这样既能及时关注到、又可以做到不遗漏。 如何判断一个新的错误的出现 刚刚提到，我们通过聚合算法把同类的错误聚合在了一起，并且标记成了一个 issueId 。那么我们就可以通过判断这个 issueId 是不是一个新的 issueId 来实现目的。如果是的话，就代表有新增的 JS 错误。 当然这种新增的思路不仅可以用在 JS 错误这种异常数据上，也同样可以用在其他异常数据上。只要识别到了一个新增的异常，就可以自动发通知，研发就能立即关注并开始处理。 那么问题来了，所找到的 JS 错误出现的原因如果是另一个同事写的代码导致的，应该怎么办？ 是直接告知他去修复这个问题呢？还是先不管了？或者有没有办法，能够自动把这个“锅”给到他，这样尴尬的问题就解决了。 线上 bug 自动分“锅” 手动指定处理人的方式比较生硬，完全依赖团队的主动性。实际上，既然已经知道原始堆栈，如果还能知道线上代码对应的仓库，我们就可以做得更细致一些。比如根据对应报错的代码行，结合 Gitlab / Github 的 open-api ，实现自动分“锅”。 如何找到某条 JS 错误对应的处理人 以 Git Blame 为例，通过下面的命令就能获取到特定文件对应行的相关 commit 信息，包括提交者/ 改动内容 / 提交时间，足够定位谁是处理人。 git blame -L &lt;range&gt; &lt;file&gt; file 对应是文件路径，也就是解析出来的原始堆栈的文件路径信息 range 对应的是查找的范围，也就是解析出来的原始堆栈的行号范围 分“锅”不够准？ 默认用来 blame 的文件都是最新版本，但线上跑的不一定是最新版本的代码。 我们可以认为一次新��发布就是一个新版本的产生，不同版本的代码可能发生行的变动，从而影响实际代码的行号。如果无法将线上运行版本和用来 blame 的文件版本对齐，就很有可能突然背“锅”。 因此****我们需要知道两个问题：线上发生的错误是属于哪个版本的？ 如何拿到对应版本的仓库文件代码？ 问题一比较好实现，在编译时注入一个版本的环境变量，保证监控时能够带上这个信息就行。 import client from '@apmplus/web' client('init', { ... release: 'v0.1.10' ... }) 问题二不好解决，仓库代码不可能给到监控平台方，更别说拿到对应版本的仓库代码了。 其实不用拿到整个仓库代码，也可以做一些 commits 关联来实现，通过相关的二进制工具，在代码发布前的脚本中，将 commits 关联上同一个版本号。这样线上发生 JS 错误后，我们就可以通过线上报错的版本找到原始代码文件对应的版本，再通过前面提到的 Gitlab / Github 的 open-api 定位到真正的处理人，就可以直接通知对应的处理人处理问题。 由此，JS 错误监控实现了闭环。 欢迎使用 目前字节的这套前端监控解决方案已同步在火山引擎上，接入即可对 Web 端真实数据进行实时监控、报警归因、聚类分析和细节定位，解决白屏、性能瓶颈、慢查询等关键问题，欢迎体验。 扫描下方二维码，立即申请免费使用⬇️ ","link":"https://www.youmeng.me/post/qian-duan-jian-kong-xi-lie-2-or-liao-liao-js-cuo-wu-jian-kong-na-xie-shi-er/"},{"title":"前端监控系列1｜ 字节的前端监控SDK是怎样设计的","content":" 原文链接：URL Source: https://juejin.cn/post/7125622436669685774 Markdown Content: 作者：彭莉，火山引擎 APM 研发工程师，2020年加入字节，负责前端监控 SDK 的开发维护、平台数据消费的探索和落地。 摘要 字节内部监控环境多样（ Web 应用、小程序、Electron 应用、跨端应用等等）， SDK 如何保证底层逻辑的复用、上层逻辑的解耦。 在业务庞杂、监控需求多样的背景下， SDK 如何做到足够灵活，如何实现插件化，并且支持业务自行扩展的。 大型 C 端业务非常注重业务自身的正确性和性能，监控 SDK 如何保证原有业务的正确性；如何保持 SDK 自身的性能，减少对业务的影响。 接入业务众多，上报量级近千万 QPS ，在日常需求迭代中， SDK 是如何确保自身稳定性的。 逻辑解耦 前端的领域广阔，所以作为前端监控，也不只局限在浏览器环境，需要同时解决小程序、 Electron 、 Nodejs 等等其他环境的监控需求。不同环境之间差异巨大，从提供的配置项，到监控的功能、上报的方式都会不一样。 一个 SDK 不可能既支持多环境，又满足体积小、功能全面的要求，这本身互相矛盾。只要兼容其他环境，打包进来的代码会导致体积变大，因此设计之初的目标就是同一套设计组装成不同的 SDK 。此设计的第一要务是要逻辑解耦。虽然多环境下差异很大，但要做的事情是一样的，比如配置、采集数据、组装数据、上报数据。 我们设计了五个角色，每个角色只需要实现约定的接口即可。这样就保证了不同的环境下，各个角色合作的方式是相同的，在实现了一套内核模版后，不同的监控 SDK 就可以快速搭建出来。 Monitor 收集器 ，主动或被动地采集特定环境下的原始数据，组装为平台无关事件。 Monitor 有若干个，每一个 Monitor 对应一个功能，比如关于 JS 错误的监控是一个 Monitor ，关于请求的监控又是另一个 Monitor 。 Builder 组装器，负责将收集器上报的平台无关事件转换为特定平台的上报格式。 主要负责包装特定环境下的上下文信息。在浏览器环境下，上下文信息包括页面地址、网络状态、当前时间等等，再结合收到的 Monitor 的数据，完成上报格式的组装。 Sender 发送器，负责发送逻辑，比如批量，重试等功能。 监控 SDK 的 Sender 都是 BatchSender ，它会负责维护一个缓存队列，按照一定的队列长度或者缓存时间间隔来聚合上报数据，会开放一些方法自定义缓存队列长度和缓存间隔时间，也支持立即上报和清空队列等操作。 特定环境下的 Sender 也需要负责处理一些边缘 case ，比如浏览器环境下的 Sender 在页面关闭时，需要使用 sendBeacon 立即上报所有队列数据，以免漏报。 在实际实践中，我们对 Sender 进行了进一步抽象， Sender 不会内置发送的能力，关于如何发送数据，不同环境依赖的 API 不同，因此会由 Client 在创建 Sender 时将具体的发送能力传入 Sender 中。 ConfigManager 配置管理器，负责配置逻辑，比如合并初始配置和用户配置、拉取远端配置等功能。 一般需要传入默认配置，支持用户手动配置，当配置完成时， ConfigManager 会变更 ready 状态，所以它也支持被订阅，以便当 ready 时或者配置变更时通知到订阅方。 export interface ConfigManager&lt;Config&gt; { setConfig: (c: Partial&lt;Config&gt;) =&gt; Config getConfig: () =&gt; Config onChange: (fn: () =&gt; void) =&gt; void onReady: (fn: () =&gt; void) =&gt; void } Client 实例主体，负责串联配置管理器、收集器、组装器和发送器，串通整个流程，同时提供生命周期监听以供扩展 SDK 功能。 下面是一段方便理解串联过程的伪代码，仅作参考。 export const createClient = ({ configManager, builder, sender }) =&gt; { let inited = false let started = false let preStartQueue = [] const client = { init: (config) =&gt; { configManager.setConfig(config) configManager.onReady(() =&gt; { preStartQueue.forEach((e) =&gt; { this.report(e) }) started = true }) inited = true } report: (data) =&gt; { if (!started) { preStartQueue.push(data) } else { const builderData = builder.build(data) builderData &amp;&amp; sender.send(builderData) } } } return client } const client = createClient({ configManager, builder, sender }) monitors.forEach((e) =&gt; { e(client) }) 角色之间足够抽象，互相独立、各司其职。比如 Monitor 只负责收集，并不知道最终上报的具体格式；Builder 只做组装，组装完成后交给实例主体 Client ，由 Client 交给 Sender ；Sender 不知道收到的具体事件格式，只负责完成发送。 开放丰富的生命周期 监控做的事情就像一条单纯的流水线：初始化 =&gt; 采集数据 =&gt; 组装数据 =&gt; 上报数据，我们希望能在不同阶段执行各种操作，但又不希望直接将逻辑耦合在代码，这样不利于后期的迭代维护，也会导致体积一步步增加，走向重构的必然结果。 于是我们决定让内核模版提供规范的生命周期，所有的功能都借助生命周期的监听来实现，这样不仅解决了体积不断膨胀的问题，也让 SDK 易于扩展。 基于监控 SDK 的各个阶段，我们明确了六个主要的生命周期，命名也比较贴切，从上到下分别是： 初始化 =&gt; 开启上报 =&gt; Monitor 监控到数据，传递给 Client =&gt; 包装数据 =&gt; 发送数据 =&gt; 销毁实例。 基于这些生命周期，我们提供了十个生命周期钩子，主要分为两类： 回调类：只执行回调，不影响流程继续执行，比如 init / start / beforeConfig / config 等等。 处理类：执行并返回修改后的有效值，如果返回无效值，将不再往下执行，终止上报，比如 report / beforeBuild / build / beforeSend 等等。 如何实现插件化 良好的生命周期是插件化的基础， 基于这些生命周期我们就能实现各种各样的插件。 举个例子，我们需要为 Monitor 采集到的数据包装事件发生时的上下文，可以通过这种方式：监听 report ，劫持到数据，重新包装，再传递给 Client 。 // 一个包装上下文的插件 export const InjectEnvPlugin = (client: WebClient) =&gt; { client('on', 'report', (ev: WebReportEvent) =&gt; { return addEnvToSendEvent(ev) }) } // 应用此插件 InjectEnvPlugin(client) 再举个例子，我们需要新监控一类数据，可以通过这种方式：监听实例主体 Client 当前的状态，在 Client ready 的时候（用户配置完成时），开始收集数据。在收集到数据时，将数据传回 Client 即可。 // 一个监听数据的插件 export const MonitorXXPlugin = (client: WebClient) =&gt; { client('on', 'init', () =&gt; { const data = listenXX(); client('report', data) }) } 在 SDK 内, 基本都是插件，常规的数据采集是一个个插件，其他的比如采样、包装上下文、异步加载等功能，也都是各自独立的插件。 业务如何自行扩展 简单的扩展，一般可以靠生命周期钩子函数来完成，常见的需求就是在数据发送前做一些手动的过滤、安全脱敏等等。 举个例子，我们想要在页面地址包含 '/test' 时不上报任何数据，可以通过下面的代码来实现。 import client from '@apmplus/web' client('on', 'beforeSend', (ev) =&gt; { if (ev.common.url.includes('/test')) { return false } return ev }) 但如果有高阶的需求，比如想写一个插件能提供给团队的其他人用，上面的方式就不再适用。如果插件太复杂，其他人需要复制一大段代码，用起来不太优雅。 基于这个需求， SDK 设计了一个自定义插件的传递协议，可以在初始化时将自定义插件传递给 Client ， Client 将会在初始化时执行传入的 setup 方法，在实例销毁时执行传入的 tearDown 方法来销毁副作用。 export interface Integration&lt;T extends AnyClient&gt; { name: string setup: (client: T) =&gt; void tearDown?: () =&gt; void } 可以注意到，接口约定的实例类型是 AnyClient ，这个协议并不在意是什么类型的 Client ，实际的 Client 类型由 SDK 来定义，比如 Web SDK 拿到的是 WebClient ， Electron SDK 拿到的是 ElectronClient 。 业务可以自行发布一个插件包，插件的实现可以是直接返回一个对象，或一个方法。允许用户传入一些配置，返回一个对象，只要这个对象满足上面的 Integration 类型即可。 import client from '@apmplus/web' import CustomPlugin from 'xxx' client('init', { ... integrations: [CustomPlugin({ config: {} })] ... }) 如何按需加载 为了方便使用，默认情况下，我们会集成所有的监控功能。但这并不是所有业务都需要的，有的业务只关心 JS 错误，其他的功能都不想要，这应该怎么解决呢？ 为此 SDK 导出了一个最小的实例，这个实例只引入通用的插件，但是不引入数据采集类的插件，而具体要采集哪些功能由用户在 integrations 上按需配置。 import { createMinimalBrowserClient } from '@apmplus/web' import { jsErrorPlugin } from '@apmplus/integrations' // 创建一个最小的实例 const client = createMinimalBrowserClient() client('init',{ ... // 按需引入需要采集的监控功能 integrations: [jsErrorPlugin()], ... }) 如何保证原有业务的正确性 接入监控 SDK 的目的是为了发现问题，如果监控 SDK 的问题导致业务受到了影响，不免本末倒置。加上绝大部分的字节前端业务都接入了这个 SDK ，如果出现问题，影响范围和损失都很巨大。因此保证原有业务的正确性远远比监控本身更重要。 SDK 会首先将对业务有影响的 敏感代码 使用 try catch 包裹起来，确保即使发生了错误也不影响业务。比如 hook 类的操作， hook XHR 和 Fetch 等等。这个操作，要做到胆大心细，同时 try catch 的范围能小则小。 其次是监控 SDK 自身的错误。我们会将 SDK 自身的 关键代码 包裹 try catch ，确保一个错误不会影响整个监控流程。单纯的 try catch 将错误吞掉解决不了问题，这些错误可能导致某些监控数据没有收集完全，影响监控的完整性。因此 SDK 实现了一个 ObserveSelfErrorPlugin ，用于收集 SDK 自身的错误并上报。 同时在字节内部，我们会针对上报所有的上报数据进行清洗，带有 SDK 自身堆栈的数据会统一消费一份到另一处，便于从宏观上观察 SDK 的出错情况，及时发现问题。 这样既确保了业务的正确性，也确保了监控 SDK 的正确性。 如何减少对业务的影响 绝大部分的业务都是使用监控 SDK 来自动上报性能数据以此来监控业务的性能，这也隐含着对监控 SDK 最基本的要求：不能带来性能问题。 最重要的就是不能影响业务的首屏渲染，为此我们把 Monitor 类的插件分为两类，一是需要立即监听的，先加载；二是不需要的立即监听的，延后加载。比如路由变化的监听、请求的监听，如果延后会导致数据遗漏，就属于第一类；像静态资源性能监控这样晚一点执行也并不会遗漏的，就属于第二类。 除此之外， SDK 本身的性能评估也非常重要。单个插件的执行耗时多少，插件带来的副作用的耗时又是多少，这些都是基本的评估点。基于字节内部提供的性能工具，我们编写了完善的 Benchmark 性能测试，在代码 MR 的时候会触发相应的测试任务，另外也有固定周期来定时执行测试任务，任务异常时不能发版， SDK 的性能由此保证。 当然尽可能缩小 SDK 的体积也能直接减少对业务的影响，这块内容涉及较广，留作后续分说。 如何尽早开始监听 监听不遗漏的前提是事件发生在开始监控之后。 但是一些超高优的事件，比如 JS 错误，发生时机可能超级靠前，等不到监控脚本加载完成。所以监控 SDK 针对 script 的接入方式会提供一个简短的脚本，让用户内联在页面中。它的作用是提前开始监听，保证高优的事件不被遗漏。 它还有另一个巧用：缓存调用命令。 监控脚本是异步加载的，因此会先挂载一个空函数，确保调用不报错；同时把对实例主体 Client 的调用命令缓存下来，记录下调用的时间和页面地址，确保能正确组装数据；等到监控脚本加载完成时再顺序执行，以此确保调用不遗漏。示例如下： window[globalName] = function (m) { const onceArguments = [].slice.call(arguments) onceArguments.push(Date.now(), location.href) ;window[globalName].precolletArguments.push(onceArguments) } window[globalName].precolletArguments = [] 当然如果使用 npm 包接入的话，依然会有预收集的逻辑，因为 npm 包不会挂全局变量，所以逻辑稍微有一些不同，同时受限于引入的顺序，执行的时机会稍晚一些。 如何保证SDK的质量 SDK 作为服务于字节唯一的前端监控产品，上报数据的流量近千万 QPS ，需要有严格的质量把控。 SDK 有完善的单元测试，每一个插件，每一个方法，都会单独编写测试用例。以及完善的自动化测试，对于整个 SDK 的所有默认行为以及各个配置项对应的行为有完整的用例覆盖。每次变动都需要补充对应的相关用例，且每次 MR 都要测试通过才能合入预发布分支，这样才能做到心中不慌。此外，会有预发布验证环节，验证改动的预期效果。如果改动的地方比较敏感，会找站点合作方灰度一段时间后发布正式版本。发布后的一段时间内我们也会密切的关注整体的流量情况，确认是否存在异常上涨和下降，是否有新增的 SDK 相关异常。 由此， SDK 的质量得以保证。 欢迎使用 现在这套前端监控服务已经同步在了火山引擎上，接入即可对 Web 端真实数据进行实时监控、报警归因、聚类分析和细节定位，解决白屏、性能瓶颈、慢查询等关键问题，欢迎体验。 扫描下方二维码，立即申请免费使用⬇️ 关注公众号【火山引擎开发者服务】，回复【交流群】加入应用性能监控交流群。 ","link":"https://www.youmeng.me/post/qian-duan-jian-kong-xi-lie-1or-zi-jie-de-qian-duan-jian-kong-sdk-shi-zen-yang-she-ji-de-jue-jin/"},{"title":"使用Rollup高效打包Taro组件库","content":"引言 在前端工程化开发中，组件库的打包是一个关键步骤。本文将详细介绍如何使用Rollup工具来打包Taro组件库，以及如何通过配置和插件选择来优化打包过程。 Rollup的优势 Rollup以其小巧的打包体积、代码精简和高效的Tree-shaking特性脱颖而出。尽管Rollup在社区支持和插件生态上不如Webpack丰富，但其对ES2015模块的支持和Tree-shaking特性使其成为打包Taro组件库的理想选择。 项目结构与配置 项目结构遵循Taro的标准初始化模式，组件存放于src/components目录，并通过src/components/index.ts统一暴露。在package.json中添加&quot;type&quot;: &quot;module&quot;配置，确保Rollup正确处理ES6模块。 Rollup插件详解 为了支持Taro组件库的打包，我们选用了以下Rollup插件： @rollup/plugin-json：处理JSON文件。 @rollup/plugin-node-resolve：解析模块路径。 @rollup/plugin-commonjs：转换CommonJS模块。 rollup-plugin-typescript2：支持TypeScript。 rollup-plugin-babel：配置Babel以支持Taro。 rollup-plugin-postcss：处理CSS/SASS，并实现移动端像素转换。 完整Rollup配置示例 以下是Rollup的配置示例，展示了如何设置输入输出、外部依赖、插件等： import json from '@rollup/plugin-json'; import resolve from '@rollup/plugin-node-resolve'; import commonjs from '@rollup/plugin-commonjs'; import typescript from 'rollup-plugin-typescript2'; import babel from 'rollup-plugin-babel'; import postcss from 'rollup-plugin-postcss'; import clear from 'rollup-plugin-clear'; import terser from 'rollup-plugin-terser'; // ...其他插件导入 const external = ['react', 'react-dom', '@tarojs/components']; const plugins = [ clear({ targets: 'dist', watch: true }), postcss({ plugins: [autoprefixer(), cssnano(), pxtransform({ platform: 'h5' }), postUrl({ url: 'inline' }), postImport()] }), resolve({ moduleDirectory: 'node_modules' }), commonjs(), json(), babel({ runtimeHelpers: true, presets: [['taro', { framework: 'react' }]], plugins: ['@babel/plugin-transform-runtime'] }), typescript({ tsconfig: './tsconfig.json' }), // ...其他插件配置 terser() // 代码压缩 ]; export default { input: './src/index.ts', output: { format: 'esm', dir: './dist/lancooUI-Mobile', sourcemap: true, exports: 'named', preserveModules: true, preserveModulesRoot: 'src' }, external, plugins }; 打包过程中的难点与解决方案 在打包过程中，我们遇到了JSX支持、类型声明、SASS支持和像素转换等难点。通过合理配置Babel和PostCSS插件，以及对Rollup打包流程的深入理解，我们成功解决了这些问题。 踩坑经验分享 在实际打包过程中，我们遇到了一些具体问题，例如字体未打包、样式失效等。通过引入postcss-url和postcss-import插件，我们解决了这些问题。 总结 通过本文的介绍，我们了解到Rollup是一个高效且灵活的打包工具，尤其适合打包Taro组件库。虽然在配置和插件选择上可能需要一些探索，但一旦掌握，Rollup将大大提高打包效率和最终产物的质量。 ","link":"https://www.youmeng.me/post/shi-yong-rollup-gao-xiao-da-bao-taro-zu-jian-ku/"},{"title":"使用 `pnpm link` 进行本地包的链接与测试","content":"在JavaScript库开发中，经常需要在实际项目中测试库的功能。pnpm link 是一个强大的工具，它允许开发者将本地开发的包加入到其他项目中，以便于测试和调试。本文将详细介绍 pnpm link 的使用，包括两种主要的链接模式，并对一些潜在问题进行解析。 全局链接（Global Link） 全局链接允许你将库发布到本地全局环境中，从而可以轻松地在任何其他本地项目中使用它。 步骤 1: 在全局环境中发布库 首先，在库的根目录下执行 pnpm link 命令，这将创建一个全局的符号链接。 步骤 2: 将全局链接的包加入到项目 在目标项目中，使用 pnpm link &lt;package-name&gt; 命令，将全局环境中的包链接到项目中。 取消全局链接 全局取消: 在任何位置执行 pnpm remove --global &lt;package-name&gt; 来取消所有项目与该包的链接。 个别项目取消: 如果项目 package.json 中已包含该依赖，使用 pnpm unlink &lt;package-name&gt; 命令取消链接。如果 package.json 中没有包含，需要手动从 node_modules 移除相关文件。 注意事项 pnpm link -g 支持含有 bin 文件的包，允许在任何地方执行包的二进制文件。但自2022年5月起，有报告指出该功能在 pnpm 7 中存在问题，且在 8.12.1 版本中问题依旧。如果你的包包含 bin 部分，可能无法通过 link -g 指令在系统各处直接运行它的二进制文件。 目录链接（Directory Link） 目录链接允许你直接将一个本地包链接到另一个项目，而无需通过全局环境。 方法一：在目标项目中链接库 在目标项目的根目录下执行 pnpm link &lt;path-to-library&gt; 命令。 方法二：从库中链接目标项目 在库的根目录下执行 pnpm link &lt;path-to-target-project&gt; 命令。 取消目录链接 无论使用哪种方法进行目录链接，取消链接的操作都在目标项目中进行，使用 pnpm unlink &lt;package-name&gt; 命令。 总结 pnpm link 提供了一种在本地环境中链接包的便捷方式，类似于 npm link 和 yarn link。尽管 pnpm 的官方文档提供了基本的使用说明，但在实际应用中，可能需要更多的细节和特定情境的处理。本文旨在提供更全面的使用细节，帮助 pnpm 开发者实现更高效的开发流程。 请注意，pnpm link 的某些功能，如全局二进制，可能存在问题。随着 pnpm 的不断更新和改进，我们期待这些问题在未来版本中得到解决。本文将适时更新，以提供最新信息。 ","link":"https://www.youmeng.me/post/shi-yong-pnpm-link-jin-xing-ben-di-bao-de-lian-jie-yu-ce-shi/"},{"title":"如何写好提示词（Prompt）？","content":"引言 在与人工智能（AI）的互动中，提示词（Prompt）是引导AI理解并回应我们需求的关键。本文将分享一些有效的编写提示词的策略。 提示词的定义 提示词是告知AI如何理解问题并进行回复的指令。编写良好的提示词可以提升问答体验和交互质量。 CO-STAR 框架 CO-STAR是一个构建有效提示词的框架，包含以下要素： C (Context) 上下文： 提供任务背景信息。 O (Objective) 目标： 明确任务要求。 S (Style) 风格： 指定期望的写作风格。 T (Tone) 语气： 设置回应的情感语调。 A (Audience) 受众： 识别目标受众。 R (Response) 响应： 规定输出的格式。 使用示例 例如，如果你想为公司的新产品撰写Facebook帖子，可以这样构建提示词： # CONTEXT（上下文） 我想推广公司的新产品。我的公司名为 Alpha，新产品名为 Beta，是一款新型超快速吹风机。 # OBJECTIVE（目标） 帮我创建一条 Facebook 帖子，目的是吸引人们点击产品链接进行购买。 # STYLE（风格） 参照 Dyson 等成功公司的宣传风格。 # TONE（语调） 说服性 # AUDIENCE（受众） 我们公司在 Facebook 上的主要受众是老年人。 # RESPONSE（响应） 保持 Facebook 帖子简洁而深具影响力。 使用分隔符进行文本分段 分隔符帮助AI辨识提示中的独立意义单元。推荐使用XML标签作为分隔符，因为AI能够理解其结构。 示例 例如，情感分类任务的提示词可以这样构建： &lt;classes&gt; 正面 负面 &lt;/classes&gt; &lt;example-conversations&gt; [Agent]: 早上好，今天我能如何帮助您？ [Customer]: 这个产品太糟糕了... &lt;/example-conversations&gt; &lt;example-classes&gt; 负面 正面 &lt;/example-classes&gt; 利用大语言模型（LLM）的系统提示创建问答机制 系统提示是向AI提供的额外指示，帮助AI理解如何回应。 示例 系统提示可以这样构建： 您需要用这段文本来回答问题：[插入文本]。请按照 {&quot;问题&quot;: &quot;答案&quot;} 的格式来回答。 如果文本信息不足以回答问题，请以&quot;NA&quot;作答。 高阶用法：仅用LLM分析数据集 讨论了LLM在数据分析方面的擅长和不擅长的领域，并提供了一个使用LLM进行客户数据集分析的示例。 应用LLM分析数据集的技巧 简化任务为步骤。 标记并引用中间输出。 优化响应格式。 分离任务指令和数据集。 结论 编写有效的提示词可以极大提升与AI的交互体验。通过CO-STAR框架、合理使用分隔符和系统提示，我们可以更精确地指导AI，实现更高质量的对话和任务完成。 ","link":"https://www.youmeng.me/post/ru-he-xie-hao-ti-shi-ci-prompt/"},{"title":"vercel+cloudflare配合绕过vercel项目无法访问问题","content":" 在vercel项目的Setting中增加自定义域名 在cloudflare中绑定你这个域名（已绑定的忽略此步骤） 在cloudflare对应的域名下增加dns 保存即可 ","link":"https://www.youmeng.me/post/vercelcloudflare-pei-he-rao-guo-vercel-xiang-mu-wu-fa-fang-wen-wen-ti/"},{"title":"如何通过飞书API获取多维表格数据","content":"飞书（Feishu）作为一款强大的企业协作工具，提供了开放API，允许开发者通过程序访问和操作多维表格（Bitable）数据。本文将介绍如何通过飞书API获取多维表格数据。 步骤一：注册开发者账号和获取API凭证 首先，需要在飞书开发者平台上注册一个开发者账号，并创建一个应用。完成注册后，你会获得两个重要的凭证：App ID和App Secret。 步骤二：获取访问令牌 接下来，使用App ID和App Secret获取访问令牌（Access Token）。发送POST请求到飞书的认证接口： POST https://open.feishu.cn/open-apis/auth/v3/app_access_token/internal/ { &quot;app_id&quot;: &quot;your_app_id&quot;, &quot;app_secret&quot;: &quot;your_app_secret&quot; } 飞书会返回一个响应，其中包含访问令牌： { &quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;, &quot;app_access_token&quot;: &quot;your_access_token&quot;, &quot;expire&quot;: 7200 } 这个访问令牌有效期为7200秒（2小时），需要定期刷新。 步骤三：获取表格数据 使用获取到的访问令牌，调用多维表格API来获取表格数据。发送GET请求到飞书的多维表格数据接口： GET https://open.feishu.cn/open-apis/bitable/v1/apps/{app_token}/tables/{table_id}/records Host: open.feishu.cn Authorization: Bearer your_access_token 其中，app_token是应用标识，table_id是表格ID。请求头中包含访问令牌。 飞书会返回一个包含表格数据的响应： { &quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;, &quot;data&quot;: { &quot;items&quot;: [ { &quot;record_id&quot;: &quot;recxxxxxxx&quot;, &quot;fields&quot;: { &quot;字段名1&quot;: &quot;值1&quot;, &quot;字段名2&quot;: &quot;值2&quot; } }, ... ] } } 示例代码 以下是一个使用Python和requests库的示例代码，帮助你快速上手： import requests # 获取访问令牌 def get_access_token(app_id, app_secret): url = &quot;https://open.feishu.cn/open-apis/auth/v3/app_access_token/internal/&quot; payload = { &quot;app_id&quot;: app_id, &quot;app_secret&quot;: app_secret } response = requests.post(url, json=payload) return response.json().get(&quot;app_access_token&quot;) # 获取表格数据 def get_table_data(app_token, table_id, access_token): url = f&quot;https://open.feishu.cn/open-apis/bitable/v1/apps/{app_token}/tables/{table_id}/records&quot; headers = { &quot;Authorization&quot;: f&quot;Bearer {access_token}&quot; } response = requests.get(url, headers=headers) return response.json() # 替换为你的App ID和App Secret app_id = &quot;your_app_id&quot; app_secret = &quot;your_app_secret&quot; app_token = &quot;your_app_token&quot; table_id = &quot;your_table_id&quot; # 获取访问令牌 access_token = get_access_token(app_id, app_secret) # 获取表格数据 table_data = get_table_data(app_token, table_id, access_token) print(table_data) 将上面的代码复制到你的Python环境中，替换相应的App ID、App Secret、App Token和Table ID，即可获取飞书多维表格的数据。 总结 通过飞书API获取多维表格数据的过程包括注册开发者账号、获取访问令牌和调用API获取数据。希望本文能帮助你更好地理解和使用飞书的API，提高工作效率。如果你有任何问题或建议，欢迎在评论区留言交流。 希望这篇文章能够更符合你的要求。 ","link":"https://www.youmeng.me/post/ru-he-tong-guo-fei-shu-api-huo-qu-duo-wei-biao-ge-shu-ju/"},{"title":"深入理解 `promiseWithResolvers` 与单例 API 包装处理重复请求","content":"在现代 Web 应用中，我们经常会遇到这样的场景：多个组件在页面加载时同时请求相同的数据。如果不加以控制，这些重复请求不仅会浪费网络资源，还会增加服务器负担，甚至可能导致数据不一致的问题。为了解决这一问题，我们可以使用一种称为“单例请求”的技术。本文将深入探讨如何使用 promiseWithResolvers 和单例 API 包装来高效处理重复请求。 什么是 promiseWithResolvers？ promiseWithResolvers 是一个实用的工具函数，它允许我们创建一个 Promise，并在外部控制其 resolve 和 reject。它的核心思想是将 Promise 的控制权交给调用者，以便在合适的时机手动触发 Promise 的状态变更。 promiseWithResolvers 的实现 首先，让我们看看 promiseWithResolvers 的实现： type PromiseState = 'pending' | 'resolved' | 'rejected'; export function promiseWithResolvers&lt;T = unknown&gt;() { let resolve: (value: T | PromiseLike&lt;T&gt;) =&gt; void; let reject: (reason?: any) =&gt; void; let finallyHandler: (() =&gt; void) | null = null; let status: PromiseState = 'pending'; const promise = new Promise&lt;T&gt;((res, rej) =&gt; { resolve = (value) =&gt; { status = 'resolved'; res(value); if (finallyHandler) { finallyHandler(); } }; reject = (reason) =&gt; { status = 'rejected'; rej(reason); if (finallyHandler) { finallyHandler(); } }; }).finally(() =&gt; { if (finallyHandler) { finallyHandler(); } }); return { promise, resolve, reject, finally: (handler: () =&gt; void) =&gt; { finallyHandler = handler; }, getStatus: () =&gt; status }; } 代码解析 状态管理：通过 status 属性，我们可以跟踪 Promise 的当前状态（pending、resolved 或 rejected）。 控制权外露：resolve 和 reject 方法被外露，使得调用者可以在适当的时机手动触发 Promise 的状态变更。 清理机制：通过 finally 方法，我们可以在 Promise 结束时执行清理操作，确保资源得以释放。 实战：单例 API 包装 为了更好地理解 promiseWithResolvers 的应用场景，让我们来看一个实际例子：如何使用它来实现单例 API 包装，从而避免重复请求。 假设我们有一个获取用户信息的 API getUser，我们希望在任何时候发起的所有 getUser 请求都只会产生一个实际的网络请求，并且所有调用者都能共享同一个结果。 import { Http } from 'path-to-http'; // 假设 Http 是你的 HTTP 库 let singletonPromise: ReturnType&lt;typeof promiseWithResolvers&gt; | null = null; export function getUser() { if (!singletonPromise) { singletonPromise = promiseWithResolvers(); singletonPromise.finally(() =&gt; { singletonPromise = null; // 请求完成后清理实例 }); Http.get( '/auth/user', {}, ) .then((res) =&gt; { if (res?.data?.userKey) { singletonPromise.resolve(res); } }) .catch((error) =&gt; { singletonPromise.reject(error); }); } return singletonPromise.promise; } 代码解析 单例模式：通过 singletonPromise 变量，我们确保在请求完成之前，所有调用都指向同一个 Promise 实例。 请求逻辑：调用 Http.get 进行实际的网络请求，并在成功时解析响应数据，更新日志，最后调用 resolve 方法。 错误处理：在请求失败时，调用 reject 方法。 清理机制：通过 finally 方法，我们在请求完成后清理 singletonPromise，以便下次请求可以创建新的 Promise。 结语 通过 promiseWithResolvers 和单例 API 包装，我们可以高效地处理重复请求，确保在任何时候发起的所有相同请求都只会产生一个实际的网络请求，并且所有调用者都能共享同一个结果。这不仅优化了网络资源的使用，还提高了应用的性能和稳定性。 希望本文能为你提供启发，帮助你在实际项目中更好地处理类似问题。如果你有任何疑问或建议，欢迎在评论区讨论。Happy coding! ","link":"https://www.youmeng.me/post/shen-ru-li-jie-promisewithresolvers-yu-dan-li-api-bao-zhuang-chu-li-chong-fu-qing-qiu/"},{"title":"小程序中获取scrollView内容的真实宽度","content":"在小程序里通常情况下是拿不到scrollView内部内容的真实宽度的，可以通过给scrollView的子元素增加css width: max-content来解决这个问题。增加之后就可以获取到子元素的真实宽度 图片展示 scrollView的宽度（355px） scrollView内部直接子元素的宽度（没加width: max-content前）（355px） scrollView内部直接子元素的宽度（加width: max-content后） 代码结构 ","link":"https://www.youmeng.me/post/xiao-cheng-xu-zhong-huo-qu-scrollview-nei-rong-de-zhen-shi-kuan-du/"},{"title":"如何使用纯CSS实现中间省略号","content":"在前端开发中，我们经常需要处理文本溢出的问题。对于长文本，通常会使用省略号来表示被截断的部分。Google了半天 基本上都是两种方案 使用js+css算字数的方案：对于动态宽度的自适应不太满足💔 direction: rtl; 文字倒序的方案：半年之后再看这段代码我都不知道是做什么的💔 下面是我的flex方案，期望对你有用。 纯CSS实现中间省略号 首先，让我们来看一下如何使用CSS实现中间省略号。 主要是使用了flex的两个属性 flex-grow和flex-shrink，左边可缩小不可以放大，右边可放大不可缩小。 以下是一个SCSS代码片段： .title { display: flex; align-items: center; justify-content: space-between; .left { flex-grow: 0; flex-shrink: 1; overflow: hidden; text-overflow: ellipsis; -webkit-line-clamp: 1; display: -webkit-box; -webkit-box-orient: vertical; } .right { flex-grow: 1; flex-shrink: 0; } } 实例展示 为了更好地理解这个CSS代码的效果，我们来看看三个不同的示例。 样式1：只有左半边，行尾省略号 &lt;View className={classes.title}&gt; &lt;View className={classes.left}&gt; 上海虹口龙之梦店上海虹口龙之梦店上海虹口龙之梦店上海虹口龙之梦店 &lt;/View&gt; &lt;/View&gt; 样式2：左边+右边也占不满一行的情况 &lt;View className={classes.title}&gt; &lt;View className={classes.left}&gt; 北京市 &lt;/View&gt; &lt;View className={classes.right}&gt; 有41家门店 &lt;/View&gt; &lt;/View&gt; 样式3：左边+右边大于一行 要保证右边完整展示 &lt;View className={classes.title}&gt; &lt;View className={classes.left}&gt; 阿坝藏族羌族自治州 &lt;/View&gt; &lt;View className={classes.right}&gt; 有1家门店 &lt;/View&gt; &lt;/View&gt; 结语 代码比较简单上手，比上面的那两种方案实用。半年之后回来再看代码也看得懂。 ✨ ","link":"https://www.youmeng.me/post/ru-he-shi-yong-chun-css-shi-xian-zhong-jian-sheng-lue-hao/"},{"title":"在同一个 Git 仓库中并行开发多个需求：解锁 `git worktree` 的魔法","content":"在开发过程中，我们常常会遇到同时处理多个需求的情况。频繁切换分支不仅让人头疼，还容易出错。今天，我要给大家介绍一个神器——git worktree。它能让你在同一个 Git 仓库中创建多个工作目录，每个目录独立处理一个分支，从此告别频繁切换分支的烦恼！ 为什么要用 git worktree？ 想象一下，你正在开发一个超级酷的新功能，突然老板走过来，拍了拍你的肩膀：“小张，那个紧急 bug 你赶紧修一下。”你只好先把手头的工作放一边，切换到另一个分支去修 bug。修完了再切回来，结果发现刚才的工作还没保存，气得你想砸键盘。 有了 git worktree，你可以在不同的目录中同时处理多个分支，再也不用担心中断工作了！ git worktree 的基本用法 1. 创建新的工作目录 # 在当前仓库中创建一个新的工作目录，并切换到 branch-name 分支 git worktree add ../path/to/new-worktree branch-name 2. 列出所有工作目录 git worktree list 3. 移除工作目录 # 移除指定的工作目录 git worktree remove ../path/to/new-worktree 示例工作流 假设你有两个需求需要同时开发，一个叫 requirement1，另一个叫 requirement2。我们来看看如何用 git worktree 优雅地处理它们。 1. 初始化仓库和创建主工作目录 首先，确保你已经克隆了你的仓库并在主工作目录中： git clone https://github.com/your-repo.git cd your-repo 2. 创建新的工作目录并切换到特性分支 # 为第一个需求创建一个新的工作目录 git worktree add ../requirement1 feature/requirement1 # 为第二个需求创建一个新的工作目录 git worktree add ../requirement2 feature/requirement2 现在，你有三个独立的工作目录： your-repo：主工作目录，仍然在 develop 分支上。 requirement1：新工作目录，在 feature/requirement1 分支上。 requirement2：新工作目录，在 feature/requirement2 分支上。 3. 在不同的工作目录中进行开发 # 在 requirement1 工作目录中开发需求1 cd ../requirement1 # 进行开发和提交 git add . git commit -m &quot;Implement requirement 1&quot; # 在 requirement2 工作目录中开发需求2 cd ../requirement2 # 进行开发和提交 git add . git commit -m &quot;Implement requirement 2&quot; 4. 合并分支回主分支 当你完成各自的需求开发后，可以将这些分支合并回 develop 分支： # 切换回主工作目录 cd ../your-repo # 合并 feature/requirement1 分支 git checkout develop git merge feature/requirement1 # 合并 feature/requirement2 分支 git merge feature/requirement2 5. 清理工作目录 如果不再需要这些工作目录，可以将其移除： git worktree remove ../requirement1 git worktree remove ../requirement2 git worktree 的优势 并行开发：允许你在同一个仓库中同时处理多个分支，而无需频繁切换分支。 独立环境：每个工作目录都是独立的，可以避免分支之间的相互影响。 简化工作流：可以更直观地管理和查看不同分支的开发进度。 通过使用 git worktree，你可以更高效地管理多个需求的开发，减少频繁切换分支带来的麻烦，从而提高开发效率。再也不用担心老板突然的需求打断你的工作了！ 配合pnpm使用安装依赖快人一步哦~ 结语 git worktree 就像是 Git 的魔法棒，轻轻一挥，就能让你在同一个仓库中自由穿梭于不同的需求之间。希望这篇文章能帮助你更好地理解和使用 git worktree，让你的开发工作更加顺畅和高效。快去试试吧，你会爱上它的！ Happy coding! 🚀 ","link":"https://www.youmeng.me/post/zai-tong-yi-ge-git-cang-ku-zhong-bing-xing-kai-fa-duo-ge-xu-qiu-jie-suo-git-worktree-de-mo-fa/"},{"title":"如何在 Git 合并冲突后正确提交文件并通过 Husky 校验","content":"在使用 Git 进行团队协作开发时，合并冲突几乎是不可避免的。特别是当你在解决冲突后，准备提交更改时，遇到 Husky 的校验阻止了你的提交，这种情况可能会让人感到困惑和沮丧。今天，我将分享一个详细的指南，帮助你在解决冲突后正确提交更改，同时绕过 Husky 的校验问题。 问题描述 假设你正在进行一个 Git 合并操作，结果出现了冲突。你手动解决了这些冲突，并准备提交更改。然而，当你运行 git commit 时，Husky 的预提交钩子（pre-commit hook）阻止了你的提交。这是因为 Husky 在提交之前会执行一些校验，比如代码格式检查、单元测试等。如果这些校验未通过，你的提交就会被阻止。 更棘手的是，如果你直接运行 git add . 来添加所有变更文件，Git 会将所有文件的变更记录都归到你的名下，这可能不是你想要的结果。那么，如何在解决冲突后正确提交更改，并绕过 Husky 的校验呢？ 解决方案 下面是一个详细的步骤指南，帮助你解决这个问题： 解决冲突： 首先，在你的代码编辑器中手动解决冲突文件中的冲突部分。确保每个冲突都被妥善处理。 标记解决冲突的文件： 使用 git add &lt;filename&gt; 来标记你已经解决冲突的文件。这一步不会影响你的提交历史，只是告诉 Git 这些冲突已经解决了。 git add &lt;filename&gt; 继续合并过程： 接下来，你需要完成合并过程。你可以使用 git merge --continue 或 git commit 来完成合并。 git merge --continue 或者： git commit 绕过 Husky 的校验： 如果 Husky 的钩子阻止了你的提交，你可以使用 --no-verify 标志来绕过这些钩子。这是一个非常有用的选项，特别是在你确信你的更改是正确的情况下。 git commit --no-verify 提交记录变更： 最后，如果你担心所有文件的变更记录都变成你的提交，你可以在解决冲突后使用 git commit --no-verify 提交解决冲突的更改，然后再进行其他的提交操作。 完整步骤总结 手动解决冲突。 使用 git add &lt;filename&gt; 标记解决冲突的文件。 使用 git commit --no-verify 来提交解决冲突的更改。 通过这几个简单的步骤，你可以确保在解决冲突后正确提交文件，同时绕过 Husky 的校验。这不仅可以让你的工作流程更加顺畅，还能确保你的代码库保持干净和有序。 希望这个指南对你有所帮助！如果你有任何问题或建议，欢迎在评论区留言讨论。Happy coding! ","link":"https://www.youmeng.me/post/ru-he-zai-git-he-bing-chong-tu-hou-zheng-que-ti-jiao-wen-jian-bing-tong-guo-husky-xiao-yan/"},{"title":"纯CSS 实现文本强制截断并且不显示省略号的两种方法","content":" 本文讨论的是超出宽度文字截断并且不在末尾显示省略号，而非多行文本末尾添加省略号。 在前端开发中，我们经常需要处理文本内容超出容器的情况。今天我们将介绍两种纯 CSS 实现文本截断的方法：一种是使用 ch 单位设置最大字符宽度，另一种是通过设置元素高度只展示一行文字，同时使用两行省略号来隐藏超出部分。这两种方法我们都将以 SCSS 的 @mixin 形式提供。 方法一：使用 ch 单位设置最大字符宽度 优点 简单易用，适合等宽字体。 控制字符数量，确保截断精确。 缺点 仅适用于等宽字体，对于非等宽字体效果不佳。 无法控制多行文本截断。 SCSS @mixin @mixin truncate-ch($width-ch) { width: $width-ch; /* 设置最大字符宽度 */ white-space: nowrap; /* 禁止换行 */ overflow: hidden; /* 超出部分隐藏 */ text-overflow: ellipsis; /* 使用省略号 */ } 示例代码 &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;CSS Truncation with ch Unit&lt;/title&gt; &lt;style&gt; .truncate-ch { @include truncate-ch(20); /* 使用mixin */ } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;truncate-ch&quot;&gt; 这是一个超出内容的示例文本。这是一个超出内容的示例文本。这是一个超出内容的示例文本。 &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 解释 @mixin truncate-ch($width-ch): 定义一个 SCSS @mixin，接收一个参数 $width-ch，用于设置最大字符宽度。 @include truncate-ch(20);: 使用 @mixin，将最大字符宽度设置为 20 个字符宽度。 方法二：两行省略号显示，但只展示一行文字 优点 适用于任意字体和多行文本。 更灵活的布局控制。 缺点 实现稍复杂，需要使用特定的 CSS 属性。 兼容性可能有问题，部分旧版浏览器不支持。 SCSS @mixin @mixin truncate-multiline($lines: 1, $line-height) { max-height: $line-height * $lines; @include line($lines + 1) } @mixin line($lines) { overflow: hidden; text-overflow: ellipsis; -webkit-line-clamp: $lines; display: -webkit-box; -webkit-box-orient: vertical; } 示例代码 &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;CSS Multi-line Truncation&lt;/title&gt; &lt;style&gt; .truncate { @include truncate-multiline(1, 1.2em); /* 使用mixin */ } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;truncate&quot;&gt; 这是一个超出内容的示例文本。这是一个超出内容的示例文本。这是一个超出内容的示例文本。这是一个超出内容的示例文本。这是一个超出内容的示例文本。 &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 解释 @mixin truncate-multiline($lines, $line-height): 定义一个 SCSS @mixin，接收两个参数 $lines 和 $line-height，用于设置显示的行数和行高。 @include truncate-multiline(1, 1.2em);: 使用 @mixin，将显示行数设置为 1 行，行高设置为 1.2em。 总结 这两种方法分别适用于不同的场景：使用 ch 单位适合等宽字体的文本截断，而两行省略号显示但只展示一行文字的方法适用于需要更灵活控制文本显示的场景。通过将这些方法整理成 SCSS 的 @mixin，可以更方便地在项目中复用。希望这篇文章能帮助你更好地处理文本截断问题。如果你有更好的方法或建议，欢迎在评论区分享！ 希望这篇文章对你有所帮助！如果你有任何问题或需要进一步的帮助，请随时告诉我。 ","link":"https://www.youmeng.me/post/chun-css-shi-xian-wen-ben-jie-duan-de-liang-chong-fang-fa/"},{"title":"Git Commit 规范指南：保持代码库整洁和可维护性","content":"在软件开发过程中，Git commit 是一种记录代码更改的方式。良好的 Git commit 规范不仅能帮助团队更好地协作，还能使代码库更加整洁和可维护。本文将介绍一些常见的 Git commit 规范，帮助你在项目中更好地管理代码提交。 1. Commit Message 格式 一个标准的 commit message 通常分为三个部分：标题（Subject）、正文（Body）和页脚（Footer）。 标题（Subject） 标题应简洁明了，通常不超过 50 个字符。以下是一些建议： 简明扼要：标题应简短明了，传达出本次提交的主要内容。 动词开头：使用祈使句，例如 &quot;Add feature&quot; 而不是 &quot;Added feature&quot;。 首字母大写：标题的首字母应大写。 不要以句号结尾：标题结尾不要加句号。 示例： Fix bug in user authentication 正文（Body） 正文用于详细描述本次提交的内容和原因。以下是一些建议： 详细描述：对 commit 做详细描述，解释为什么需要这次更改以及更改的具体内容。 换行：每行不超过 72 个字符，便于阅读。 空行分隔：标题和正文之间应有一个空行。 示例： Fix bug in user authentication This commit fixes the issue where users were unable to log in due to a missing parameter in the authentication function. 页脚（Footer） 页脚用于补充一些额外的信息，例如关联的 issue 或破坏性更改。以下是一些建议： 关联问题：如果与某个问题（issue）或任务（task）相关，可以在页脚中注明。 BREAKING CHANGE：如果有破坏性更改，应在页脚中注明。 示例： Fix bug in user authentication This commit fixes the issue where users were unable to log in due to a missing parameter in the authentication function. Fixes #42 2. 使用标准化的提交类型 为了更好地组织和理解 commit，一些团队使用标准化的提交类型。常见的类型包括： feat：新功能（feature） fix：修复 bug docs：文档更新 style：代码格式（不影响代码运行的变动） refactor：代码重构（既不是新增功能，也不是修复 bug 的代码变动） test：增加测试 chore：构建过程或辅助工具的变动 示例： feat: add user login functionality 3. 遵循语义化版本控制（Semantic Versioning） 语义化版本控制（Semantic Versioning）是一种通过 commit message 自动生成版本号的方式。常见的规则包括： fix：表示修复 bug，会触发补丁版本号（patch version）的更新。 feat：表示新增功能，会触发次版本号（minor version）的更新。 BREAKING CHANGE：表示破坏性更改，会触发主版本号（major version）的更新。 4. 工具支持 使用一些工具可以帮助你更好地遵循提交规范，例如： Commitizen：一个帮助你生成标准化 commit message 的工具。 Husky：一个 Git 钩子工具，可以在提交前运行 lint 检查，确保 commit message 符合规范。 总结 良好的 Git commit 规范有助于提高团队协作效率，便于代码审查和历史追踪。通过遵循上述规范，可以使 commit message 更加清晰、易读和有用。希望这篇指南能帮助你在项目中更好地管理代码提交，保持代码库的整洁和可维护性。 希望这篇博客文章对你有帮助！如果有任何问题或需要进一步的修改，请随时告诉我。 ","link":"https://www.youmeng.me/post/git-commit-gui-fan-zhi-nan-bao-chi-dai-ma-ku-zheng-ji-he-ke-wei-hu-xing/"},{"title":"Taro3 里可以跑起来的第三方优秀类库","content":"待续不断搜索可以运行在 Taro3 环境下的优秀第三方类库. 特性 🎁 使用原始 npm 包, 保持原汁原味, 不做侵入性的修改. 🔧 简化配置, 搭配 @tarojsx/polyfill 使用. 🔎 完善的 Typescript 类型提示. 🔭 持续探索中... 需求 taro 3+ 安装 npm i @tarojsx/library @tarojsx/polyfill 使用 部分组件需要用到 polyfill. 更新 config/index.js 配置如下 const { TaroProvidePlugin } = require('@tarojsx/polyfill/dist/plugins') const config = { mini: { webpackChain(chain, webpack) { chain .plugin('taroProviderPlugin') .use(TaroProvidePlugin) } } } 模块 图表 AntV F2 - 让数据栩栩如生 虚拟滚动 react-window - 虚拟滚动 FixedSizeList VariableSizeList react-vtree - 虚拟滚动树 FixedSizeTree 交互动画 react-spring - 弹性物理动画 react-use-gesture - 触摸手势 测试步骤 打开微信开发者工具 CLI/HTTP 调用功能，设置 - 安全设置 - 服务端口 导入项目，目录指向当前项目文件夹。 运行 npm run test 如果提示 Failed to launch wechat web devTools，请先退出微信开发者工具。 ","link":"https://www.youmeng.me/post/taro3-li-ke-yi-pao-qi-lai-de-di-san-fang-you-xiu-lei-ku/"},{"title":"在 Taro 中实现懒加载组件，可用于瀑布流布局和组件懒加载","content":"在 Taro 中实现懒加载组件：保留元素高度的解决方案 在开发小程序时，我们常常需要处理长列表的渲染问题。为了优化性能，组件懒加载是一种非常有效的手段。然而，在实现懒加载时，我们需要确保不可见的元素仍然保留它们的高度，以避免位置变化。这篇文章将记录我在 Taro 中实现懒加载组件的过程，并分享我的解决方案。 问题描述 在我的小程序项目中，我需要渲染一个包含大量项目的长列表。为了提高性能，我决定使用懒加载技术，只在需要时加载和渲染可见的项目。然而，我遇到了一个问题：当项目不可见时，它们的高度会消失，导致整个列表的位置发生变化。这种情况会影响用户体验，特别是在快速滚动时。 解决方案 为了解决这个问题，我决定创建一个懒加载组件，该组件在不可见时保留元素的高度。具体步骤如下： 监听元素是否进入视口：使用 Taro.createIntersectionObserver 创建一个观察器。 动态获取元素高度：使用 Taro.createSelectorQuery 获取元素的高度。 保留高度：当元素不可见时，通过 paddingTop 保留高度，避免位置变化。 代码实现 1. 创建 LazyLoadComponent 组件 首先，我们创建一个 LazyLoadComponent 组件，用于包裹需要懒加载的内容。 import React, { useEffect, useRef, useState } from 'react'; import Taro from '@tarojs/taro'; import { View } from '@tarojs/components'; interface LazyLoadComponentProps { children: React.ReactNode; threshold: number; // 触发加载的阈值，需要大于100 } function LazyLoadComponent(props: LazyLoadComponentProps) { const { children, threshold } = props; const [isVisible, setIsVisible] = useState(true); const [elementHeight, setElementHeight] = useState(0); const containerRef = useRef&lt;HTMLDivElement&gt;(null); const lazyloadContainerId = useRef(`lazyload-${Math.random().toString(36).slice(2)}`); useEffect(() =&gt; { if (!containerRef.current) return () =&gt; {}; getElementBoundingClientRect(`#${lazyloadContainerId.current}`).then((res) =&gt; { setElementHeight(res?.height!); }); // 创建 IntersectionObserver const observer = Taro.createIntersectionObserver(this, { thresholds: [0.1], observeAll: false, }); observer.relativeToViewport({ top: threshold }).observe(`#${lazyloadContainerId.current}`, (res) =&gt; { if (res.intersectionRatio &gt; 0.1) { setIsVisible(true); } else { setIsVisible(false); } }); return () =&gt; { observer.disconnect(); }; }, [threshold]); return ( &lt;View id={lazyloadContainerId.current} ref={containerRef} style={{ width: isVisible ? 'auto' : '1px', height: isVisible ? 'auto' : `${elementHeight}px`, }} &gt; {isVisible ? children : null} &lt;/View&gt; ); } export default LazyLoadComponent; 2. 获取元素高度 为了获取每个元素的高度，我们定义了一个辅助函数 getElementBoundingClientRect。这个函数使用了 Taro.createSelectorQuery 来查询元素的边界矩形，并返回一个 Promise。 function getElementBoundingClientRect(selector: string) { return new Promise&lt;BoundingClientRect | undefined&gt;((resolve, reject) =&gt; { function getBounding() { const $ = Taro.createSelectorQuery(); $.select(selector) .boundingClientRect() .exec((res) =&gt; { if (res &amp;&amp; res[0]) { resolve(res[0]); } else { resolve(undefined); } }); } try { const timer = setTimeout(() =&gt; { getBounding(); }, 16); Taro.nextTick(() =&gt; { clearTimeout(timer); getBounding(); }); } catch (e) { reject(e); } }); } 3. 使用示例 我们在一个长列表中使用 LazyLoadComponent 来包裹需要懒加载的内容。 import React from 'react'; import LazyLoadComponent from './LazyLoadComponent'; const LongList = () =&gt; { const items = Array.from({ length: 10000 }, (_, index) =&gt; index + 1); return ( &lt;View&gt; {items.map(item =&gt; ( &lt;LazyLoadComponent key={item} threshold={300}&gt; &lt;View style={{ height: '100px', border: '1px solid black', margin: '10px 0' }}&gt; Item {item} &lt;/View&gt; &lt;/LazyLoadComponent&gt; ))} &lt;/View&gt; ); }; export default LongList; 代码解释 获取元素高度：使用 Taro.createSelectorQuery 获取元素的高度，并更新 elementHeight 状态。 IntersectionObserver：使用 Taro.createIntersectionObserver 创建一个观察器，监听元素是否进入视口。 保留高度：当元素不可见时，通过 paddingTop 保留高度，避免位置变化。 通过上述步骤，我们成功实现了在 Taro 中的懒加载组件，并解决了不可见元素高度消失的问题。希望这篇文章对你有所帮助！ ","link":"https://www.youmeng.me/post/zai-taro-zhong-shi-xian-lan-jia-zai-zu-jian-ke-yong-yu-pu-bu-liu-bu-ju-he-zu-jian-lan-jia-zai/"}]}